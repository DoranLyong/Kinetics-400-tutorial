{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "* [YutaroOgawa's github](https://github.com/YutaroOgawa/pytorch_advanced/blob/master/9_video_classification_eco/9-4_3_ECO_DataLoader.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import os.path as osp \n",
    "import glob \n",
    "import csv \n",
    "\n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.utils.data as data \n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PyTorch Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. make file lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(dataset_root:str) -> list: \n",
    "    \"\"\" build a path list for video frames \n",
    "    \"\"\"\n",
    "    video_list = [] \n",
    "\n",
    "    class_list = os.listdir(path=dataset_root)\n",
    "\n",
    "    for cls_item in class_list:\n",
    "        \"\"\" cls_item: 'arm wrestling', 'bungee jumping', and else...\n",
    "        \"\"\"\n",
    "        cls_path = osp.join(dataset_root, cls_item)\n",
    "        video_frame_dirs = list(filter(osp.isdir, glob.glob(osp.join(cls_path, '*'))))\n",
    "\n",
    "        video_list.extend(video_frame_dirs)\n",
    "\n",
    "    return video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./dataset/kinetics_videos/arm wrestling/ehLnj7pXnYE_000027_000037', './dataset/kinetics_videos/arm wrestling/C4lCVBZ3ux0_000028_000038', './dataset/kinetics_videos/arm wrestling/5JzkrOVhPOw_000027_000037', './dataset/kinetics_videos/arm wrestling/BdMiTo_OtnU_000024_000034', './dataset/kinetics_videos/bungee jumping/b6yQZjPE26c_000023_000033', './dataset/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012', './dataset/kinetics_videos/bungee jumping/zkXOcxGnUhs_000025_000035', './dataset/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020']\n"
     ]
    }
   ],
   "source": [
    "# test working \n",
    "dataset_root = f\"./dataset/kinetics_videos\"\n",
    "\n",
    "video_list = make_datapath_list(dataset_root)\n",
    "print(video_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. video transformation class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoTransform():\n",
    "    \"\"\"\n",
    "    동영상을 화상으로 만드는 전처리 클래스. 학습시와 추론시 다르게 작동합니다.\n",
    "    동영상을 화상으로 분할하고 있으므로, 분할된 화상을 한꺼번에 전처리하는 점에 주의하십시오.\n",
    "    \"\"\"\n",
    "    def __init__(self, resize, crop_size, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train': torchvision.transforms.Compose([\n",
    "                # DataAugumentation()  # 이번에는 생략\n",
    "                GroupResize(int(resize)),  # 화상을 한꺼번에 리사이즈\n",
    "                GroupCenterCrop(crop_size),  # 화상을 한꺼번에 center crop\n",
    "                GroupToTensor(),  # 데이터를 PyTorch 텐서로\n",
    "                GroupImgNormalize(mean, std),  # 데이터를 표준화\n",
    "                Stack()  # 여러 화상을 frames차원으로 결합시킨다\n",
    "            ]),\n",
    "            \n",
    "            'val': torchvision.transforms.Compose([\n",
    "                GroupResize(int(resize)),  # 화상을 한꺼번에 리사이즈\n",
    "                GroupCenterCrop(crop_size),  # 화상을 한꺼번에 center crop\n",
    "                GroupToTensor(),  # 데이터를 PyTorch 텐서로\n",
    "                GroupImgNormalize(mean, std),  # 데이터를 표준화\n",
    "                Stack()  # 여러 화상을 frames차원으로 결합시킨다\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img_group, phase):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            전처리 모드 지정\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리로 사용할 클래스들을 정의\n",
    "class GroupResize():\n",
    "    '''화상 크기를 한꺼번에 재조정(rescale)하는 클래스.\n",
    "    화상의 짧은 변의 길이가 resize로 변환된다.\n",
    "    화면 비율은 유지된다.\n",
    "    '''\n",
    "    def __init__(self, resize, interpolation=Image.BILINEAR):\n",
    "        '''rescale 처리 준비'''\n",
    "        self.rescaler = torchvision.transforms.Resize(resize, interpolation)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        '''img_group(리스트)의 각 img에 rescale 실시'''\n",
    "        return [self.rescaler(img) for img in img_group]\n",
    "\n",
    "\n",
    "class GroupCenterCrop():\n",
    "    '''화상을 한꺼번에 center crop 하는 클래스.\n",
    "        (crop_size, crop_size)의 화상을 잘라낸다.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, crop_size):\n",
    "        '''center crop 처리를 준비'''\n",
    "        self.ccrop = torchvision.transforms.CenterCrop(crop_size)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        '''img_group(리스트)의 각 img에 center crop 실시'''\n",
    "        return [self.ccrop(img) for img in img_group]\n",
    "\n",
    "\n",
    "class GroupToTensor():\n",
    "    '''화상을 한꺼번에 텐서로 만드는 클래스.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''텐서화하는 처리를 준비'''\n",
    "        self.to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        '''img_group(리스트)의 각 img에 텐서화 실시\n",
    "        0부터 1까지가 아니라, 0부터 255까지를 다루므로, 255를 곱해서 계산한다.\n",
    "        0부터 255로 다루는 것은, 학습된 데이터 형식에 맞추기 위함\n",
    "        '''\n",
    "\n",
    "        return [self.to_tensor(img)*255 for img in img_group]\n",
    "\n",
    "\n",
    "class GroupImgNormalize():\n",
    "    '''화상을 한꺼번에 표준화하는 클래스.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        '''표준화 처리를 준비'''\n",
    "        self.normlize = torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        '''img_group(리스트)의 각 img에 표준화 실시'''\n",
    "        return [self.normlize(img) for img in img_group]\n",
    "\n",
    "\n",
    "class Stack():\n",
    "    '''화상을 하나의 텐서로 정리하는 클래스.\n",
    "    '''\n",
    "\n",
    "    def __call__(self, img_group):\n",
    "        '''img_group은 torch.Size([3, 224, 224])를 요소로 하는 리스트\n",
    "        '''\n",
    "        ret = torch.cat([(x.flip(dims=[0])).unsqueeze(dim=0)\n",
    "                         for x in img_group], dim=0)  # frames 차원으로 결합\n",
    "        # x.flip(dims=[0])은 색상 채널을 RGB에서 BGR으로 순서를 바꾸고 있습니다(원래의 학습 데이터가 BGR이었기 때문입니다)\n",
    "        # unsqueeze(dim=0)은 새롭게 frames용의 차원을 작성하고 있습니다\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. data.Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kinetics-400의 라벨명을 ID로 변환하는 사전과, 반대로 ID를 라벨명으로 변환하는 사전을 준비\n",
    "def get_label_id_dictionary(label_dicitionary_path='./dataset/anno/kinetics_400_label_dicitionary.csv'):\n",
    "    label_id_dict = {}\n",
    "    id_label_dict = {}\n",
    "\n",
    "    with open(label_dicitionary_path, encoding=\"utf-8_sig\") as f:\n",
    "\n",
    "        # 읽어들이기\n",
    "        reader = csv.DictReader(f, delimiter=\",\", quotechar='\"')\n",
    "\n",
    "        # 1행씩 읽어, 사전형 변수에 추가합니다\n",
    "        for row in reader:\n",
    "            label_id_dict.setdefault(\n",
    "                row[\"class_label\"], int(row[\"label_id\"])-1)\n",
    "            id_label_dict.setdefault(\n",
    "                int(row[\"label_id\"])-1, row[\"class_label\"])\n",
    "\n",
    "    return label_id_dict,  id_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test working \n",
    "label_dicitionary_path = './dataset/anno/kinetics_400_label_dicitionary.csv'\n",
    "label_id_dict, id_label_dict = get_label_id_dictionary(label_dicitionary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abseiling': 0, 'air drumming': 1, 'answering questions': 2, 'applauding': 3, 'applying cream': 4, 'archery': 5, 'arm wrestling': 6, 'arranging flowers': 7, 'assembling computer': 8, 'auctioning': 9, 'baby waking up': 10, 'baking cookies': 11, 'balloon blowing': 12, 'bandaging': 13, 'barbequing': 14, 'bartending': 15, 'beatboxing': 16, 'bee keeping': 17, 'belly dancing': 18, 'bench pressing': 19, 'bending back': 20, 'bending metal': 21, 'biking through snow': 22, 'blasting sand': 23, 'blowing glass': 24, 'blowing leaves': 25, 'blowing nose': 26, 'blowing out candles': 27, 'bobsledding': 28, 'bookbinding': 29, 'bouncing on trampoline': 30, 'bowling': 31, 'braiding hair': 32, 'breading or breadcrumbing': 33, 'breakdancing': 34, 'brush painting': 35, 'brushing hair': 36, 'brushing teeth': 37, 'building cabinet': 38, 'building shed': 39, 'bungee jumping': 40, 'busking': 41, 'canoeing or kayaking': 42, 'capoeira': 43, 'carrying baby': 44, 'cartwheeling': 45, 'carving pumpkin': 46, 'catching fish': 47, 'catching or throwing baseball': 48, 'catching or throwing frisbee': 49, 'catching or throwing softball': 50, 'celebrating': 51, 'changing oil': 52, 'changing wheel': 53, 'checking tires': 54, 'cheerleading': 55, 'chopping wood': 56, 'clapping': 57, 'clay pottery making': 58, 'clean and jerk': 59, 'cleaning floor': 60, 'cleaning gutters': 61, 'cleaning pool': 62, 'cleaning shoes': 63, 'cleaning toilet': 64, 'cleaning windows': 65, 'climbing a rope': 66, 'climbing ladder': 67, 'climbing tree': 68, 'contact juggling': 69, 'cooking chicken': 70, 'cooking egg': 71, 'cooking on campfire': 72, 'cooking sausages': 73, 'counting money': 74, 'country line dancing': 75, 'cracking neck': 76, 'crawling baby': 77, 'crossing river': 78, 'crying': 79, 'curling hair': 80, 'cutting nails': 81, 'cutting pineapple': 82, 'cutting watermelon': 83, 'dancing ballet': 84, 'dancing charleston': 85, 'dancing gangnam style': 86, 'dancing macarena': 87, 'deadlifting': 88, 'decorating the christmas tree': 89, 'digging': 90, 'dining': 91, 'disc golfing': 92, 'diving cliff': 93, 'dodgeball': 94, 'doing aerobics': 95, 'doing laundry': 96, 'doing nails': 97, 'drawing': 98, 'dribbling basketball': 99, 'drinking': 100, 'drinking beer': 101, 'drinking shots': 102, 'driving car': 103, 'driving tractor': 104, 'drop kicking': 105, 'drumming fingers': 106, 'dunking basketball': 107, 'dying hair': 108, 'eating burger': 109, 'eating cake': 110, 'eating carrots': 111, 'eating chips': 112, 'eating doughnuts': 113, 'eating hotdog': 114, 'eating ice cream': 115, 'eating spaghetti': 116, 'eating watermelon': 117, 'egg hunting': 118, 'exercising arm': 119, 'exercising with an exercise ball': 120, 'extinguishing fire': 121, 'faceplanting': 122, 'feeding birds': 123, 'feeding fish': 124, 'feeding goats': 125, 'filling eyebrows': 126, 'finger snapping': 127, 'fixing hair': 128, 'flipping pancake': 129, 'flying kite': 130, 'folding clothes': 131, 'folding napkins': 132, 'folding paper': 133, 'front raises': 134, 'frying vegetables': 135, 'garbage collecting': 136, 'gargling': 137, 'getting a haircut': 138, 'getting a tattoo': 139, 'giving or receiving award': 140, 'golf chipping': 141, 'golf driving': 142, 'golf putting': 143, 'grinding meat': 144, 'grooming dog': 145, 'grooming horse': 146, 'gymnastics tumbling': 147, 'hammer throw': 148, 'headbanging': 149, 'headbutting': 150, 'high jump': 151, 'high kick': 152, 'hitting baseball': 153, 'hockey stop': 154, 'holding snake': 155, 'hopscotch': 156, 'hoverboarding': 157, 'hugging': 158, 'hula hooping': 159, 'hurdling': 160, 'hurling (sport)': 161, 'ice climbing': 162, 'ice fishing': 163, 'ice skating': 164, 'ironing': 165, 'javelin throw': 166, 'jetskiing': 167, 'jogging': 168, 'juggling balls': 169, 'juggling fire': 170, 'juggling soccer ball': 171, 'jumping into pool': 172, 'jumpstyle dancing': 173, 'kicking field goal': 174, 'kicking soccer ball': 175, 'kissing': 176, 'kitesurfing': 177, 'knitting': 178, 'krumping': 179, 'laughing': 180, 'laying bricks': 181, 'long jump': 182, 'lunge': 183, 'making a cake': 184, 'making a sandwich': 185, 'making bed': 186, 'making jewelry': 187, 'making pizza': 188, 'making snowman': 189, 'making sushi': 190, 'making tea': 191, 'marching': 192, 'massaging back': 193, 'massaging feet': 194, 'massaging legs': 195, \"massaging person's head\": 196, 'milking cow': 197, 'mopping floor': 198, 'motorcycling': 199, 'moving furniture': 200, 'mowing lawn': 201, 'news anchoring': 202, 'opening bottle': 203, 'opening present': 204, 'paragliding': 205, 'parasailing': 206, 'parkour': 207, 'passing American football (in game)': 208, 'passing American football (not in game)': 209, 'peeling apples': 210, 'peeling potatoes': 211, 'petting animal (not cat)': 212, 'petting cat': 213, 'picking fruit': 214, 'planting trees': 215, 'plastering': 216, 'playing accordion': 217, 'playing badminton': 218, 'playing bagpipes': 219, 'playing basketball': 220, 'playing bass guitar': 221, 'playing cards': 222, 'playing cello': 223, 'playing chess': 224, 'playing clarinet': 225, 'playing controller': 226, 'playing cricket': 227, 'playing cymbals': 228, 'playing didgeridoo': 229, 'playing drums': 230, 'playing flute': 231, 'playing guitar': 232, 'playing harmonica': 233, 'playing harp': 234, 'playing ice hockey': 235, 'playing keyboard': 236, 'playing kickball': 237, 'playing monopoly': 238, 'playing organ': 239, 'playing paintball': 240, 'playing piano': 241, 'playing poker': 242, 'playing recorder': 243, 'playing saxophone': 244, 'playing squash or racquetball': 245, 'playing tennis': 246, 'playing trombone': 247, 'playing trumpet': 248, 'playing ukulele': 249, 'playing violin': 250, 'playing volleyball': 251, 'playing xylophone': 252, 'pole vault': 253, 'presenting weather forecast': 254, 'pull ups': 255, 'pumping fist': 256, 'pumping gas': 257, 'punching bag': 258, 'punching person (boxing)': 259, 'push up': 260, 'pushing car': 261, 'pushing cart': 262, 'pushing wheelchair': 263, 'reading book': 264, 'reading newspaper': 265, 'recording music': 266, 'riding a bike': 267, 'riding camel': 268, 'riding elephant': 269, 'riding mechanical bull': 270, 'riding mountain bike': 271, 'riding mule': 272, 'riding or walking with horse': 273, 'riding scooter': 274, 'riding unicycle': 275, 'ripping paper': 276, 'robot dancing': 277, 'rock climbing': 278, 'rock scissors paper': 279, 'roller skating': 280, 'running on treadmill': 281, 'sailing': 282, 'salsa dancing': 283, 'sanding floor': 284, 'scrambling eggs': 285, 'scuba diving': 286, 'setting table': 287, 'shaking hands': 288, 'shaking head': 289, 'sharpening knives': 290, 'sharpening pencil': 291, 'shaving head': 292, 'shaving legs': 293, 'shearing sheep': 294, 'shining shoes': 295, 'shooting basketball': 296, 'shooting goal (soccer)': 297, 'shot put': 298, 'shoveling snow': 299, 'shredding paper': 300, 'shuffling cards': 301, 'side kick': 302, 'sign language interpreting': 303, 'singing': 304, 'situp': 305, 'skateboarding': 306, 'ski jumping': 307, 'skiing (not slalom or crosscountry)': 308, 'skiing crosscountry': 309, 'skiing slalom': 310, 'skipping rope': 311, 'skydiving': 312, 'slacklining': 313, 'slapping': 314, 'sled dog racing': 315, 'smoking': 316, 'smoking hookah': 317, 'snatch weight lifting': 318, 'sneezing': 319, 'sniffing': 320, 'snorkeling': 321, 'snowboarding': 322, 'snowkiting': 323, 'snowmobiling': 324, 'somersaulting': 325, 'spinning poi': 326, 'spray painting': 327, 'spraying': 328, 'springboard diving': 329, 'squat': 330, 'sticking tongue out': 331, 'stomping grapes': 332, 'stretching arm': 333, 'stretching leg': 334, 'strumming guitar': 335, 'surfing crowd': 336, 'surfing water': 337, 'sweeping floor': 338, 'swimming backstroke': 339, 'swimming breast stroke': 340, 'swimming butterfly stroke': 341, 'swing dancing': 342, 'swinging legs': 343, 'swinging on something': 344, 'sword fighting': 345, 'tai chi': 346, 'taking a shower': 347, 'tango dancing': 348, 'tap dancing': 349, 'tapping guitar': 350, 'tapping pen': 351, 'tasting beer': 352, 'tasting food': 353, 'testifying': 354, 'texting': 355, 'throwing axe': 356, 'throwing ball': 357, 'throwing discus': 358, 'tickling': 359, 'tobogganing': 360, 'tossing coin': 361, 'tossing salad': 362, 'training dog': 363, 'trapezing': 364, 'trimming or shaving beard': 365, 'trimming trees': 366, 'triple jump': 367, 'tying bow tie': 368, 'tying knot (not on a tie)': 369, 'tying tie': 370, 'unboxing': 371, 'unloading truck': 372, 'using computer': 373, 'using remote controller (not gaming)': 374, 'using segway': 375, 'vault': 376, 'waiting in line': 377, 'walking the dog': 378, 'washing dishes': 379, 'washing feet': 380, 'washing hair': 381, 'washing hands': 382, 'water skiing': 383, 'water sliding': 384, 'watering plants': 385, 'waxing back': 386, 'waxing chest': 387, 'waxing eyebrows': 388, 'waxing legs': 389, 'weaving basket': 390, 'welding': 391, 'whistling': 392, 'windsurfing': 393, 'wrapping present': 394, 'wrestling': 395, 'writing': 396, 'yawning': 397, 'yoga': 398, 'zumba': 399}\n"
     ]
    }
   ],
   "source": [
    "#print(id_label_dict)\n",
    "print(label_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, video_list, label_id_dict, num_segments, phase, transform, img_tmpl='image_{:05d}.png'):\n",
    "\n",
    "        self.video_list = video_list  # 동영상 폴더의 경로 리스트\n",
    "        self.label_id_dict = label_id_dict  # 라벨명을 id로 변환하는 사전형 변수\n",
    "        self.num_segments = num_segments  # 동영상을 어떻게 분할해 사용할지를 결정\n",
    "        self.phase = phase  # train or val\n",
    "        self.transform = transform  # 전처리\n",
    "        self.img_tmpl = img_tmpl  # 읽어들일 이미지 파일명의 템플릿\n",
    "\n",
    "    def __len__(self):\n",
    "        '''동영상 수를 반환'''\n",
    "        return len(self.video_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        전처리한 이미지들의 데이터와 라벨, 라벨 ID를 취득\n",
    "        '''\n",
    "        imgs_transformed, label, label_id, dir_path = self.pull_item(index)\n",
    "        return imgs_transformed, label, label_id, dir_path\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        '''전처리한 화상들의 데이터와 라벨, 라벨 ID를 취득'''\n",
    "\n",
    "        # 1. 이미지들을 리스트에서 읽기\n",
    "        dir_path = self.video_list[index]  # 이미지가 저장된 폴더\n",
    "        indices = self._get_indices(dir_path)  # 읽어들일 화상 idx를 구하기\n",
    "        img_group = self._load_imgs(\n",
    "            dir_path, self.img_tmpl, indices)  # 리스트로 읽기\n",
    "\n",
    "        # 2. 라벨을 취득해 id로 변환\n",
    "        label = (dir_path.split('/')[3].split('/')[0])\n",
    "        label_id = self.label_id_dict[label] # id를 취득\n",
    "\n",
    "        # 3. 전처리 실시\n",
    "        imgs_transformed = self.transform(img_group, phase=self.phase)\n",
    "\n",
    "        return imgs_transformed, label, label_id, dir_path\n",
    "\n",
    "    def _load_imgs(self, dir_path, img_tmpl, indices):\n",
    "        '''이미지를 한꺼번에 읽어들여, 리스트화하는 함수'''\n",
    "        img_group = []  # 화상을 저장할 리스트\n",
    "\n",
    "        for idx in indices:\n",
    "            # 화상 경로 취득\n",
    "            file_path = os.path.join(dir_path, img_tmpl.format(idx))\n",
    "\n",
    "            # 화상 읽기\n",
    "            img = Image.open(file_path).convert('RGB')\n",
    "\n",
    "            # 리스트에 추가\n",
    "            img_group.append(img)\n",
    "        return img_group\n",
    "\n",
    "    def _get_indices(self, dir_path):\n",
    "        \"\"\"\n",
    "        동영상 전체를 self.num_segment로 분할했을 때의 동영상 idx의 리스트를 취득\n",
    "        \"\"\"\n",
    "        # 동영상 프레임 수 구하기\n",
    "        file_list = os.listdir(path=dir_path)\n",
    "        num_frames = len(file_list)\n",
    "\n",
    "        # 동영상의 간격을 구하기\n",
    "        tick = (num_frames) / float(self.num_segments)\n",
    "        # 250 / 16 = 15.625\n",
    "        # 동영상 간격으로 꺼낼 때 idx를 리스트로 구하기\n",
    "        indices = np.array([int(tick / 2.0 + tick * x)\n",
    "                            for x in range(self.num_segments)])+1\n",
    "        # 250frame에서 16frame 추출의 경우\n",
    "        # indices = [  8  24  40  55  71  86 102 118 133 149 165 180 196 211 227 243]\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == test working == # \n",
    "\n",
    "# vieo_list 작성\n",
    "dataset_root = f\"./dataset/kinetics_videos\"\n",
    "video_list = make_datapath_list(dataset_root)\n",
    "\n",
    "# 전처리 설정\n",
    "resize, crop_size = 224, 224\n",
    "mean, std = [104, 117, 123], [1, 1, 1]\n",
    "video_transform = VideoTransform(resize, crop_size, mean, std)\n",
    "\n",
    "\n",
    "# Dataset 작성\n",
    "# num_segments는 동영상을 어떻게 분할해 사용할지 정한다\n",
    "val_dataset = VideoDataset(video_list, label_id_dict, num_segments=16,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl='{:05d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "arm wrestling\n",
      "6\n",
      "./dataset/kinetics_videos/arm wrestling/ehLnj7pXnYE_000027_000037\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 꺼내는 예\n",
    "# 출력은 imgs_transformed, label, label_id, dir_path\n",
    "index = 0\n",
    "sample = val_dataset.__getitem__(index)\n",
    "\n",
    "print(sample[0].shape)  # 동영상의 텐서\n",
    "print(sample[1])  # 라벨\n",
    "print(sample[2])  # 라벨ID\n",
    "print(sample[3])  # 동영상 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "val_dataloader = data.DataLoader( val_dataset, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 동작 확인\n",
    "batch_iterator = iter(val_dataloader)  # 반복자로 변환\n",
    "imgs_transformeds, labels, label_ids, dir_path = next(batch_iterator)  # 1번째 요소를 꺼낸다\n",
    "\n",
    "print(imgs_transformeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f38f9a92a40eacf7671051530596ac31a08fa1747600811db2b78ca4cf9fd4a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
